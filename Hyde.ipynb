{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa2441ec-ef3d-4ec3-8aa5-3aa7bac83904",
   "metadata": {},
   "source": [
    "### Query Transformation using HyDE: Pre-retrieval optimization technique for Advanced RAG\n",
    "\n",
    "In traditional RAG , semantic meaning of documents and user query is used to find the documents that are similar to the user query. But there is one problem with this approach is that , semantic meaning of the search query is not always well represented in the document embeddings .It means document embeddings are  not perfectly aligned with search query embeddings . \n",
    "\n",
    "##### How it Works:\n",
    "* Hypothetical document generation: User query is passed to the LLM to generate hypothetical documents/answers .\n",
    "* use embedding model to encode these fake documents into embeddings.\n",
    "* Use similarity search to find the most similar document chunks to the hypothetical document embeddings.\n",
    "* Finally , use the retrieved document chunks to generate final answer.\n",
    "\n",
    "HyDE helps to improve retrieval accuracy and reduce hallucinations . It only works when LLM has some knowledge about the asked question. If LLM produce wrong hypothetical answer to the user query , then final retrieved document chunks will not be relevant. So this is one of the limitation of this method. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c911dde-0079-4306-a026-57e4d885a7db",
   "metadata": {},
   "source": [
    "## Implementation using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a2e81ad-fd05-4e13-bd70-3f38a74cef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a323ad9c-7f92-4c90-a61a-a44d8bac8dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import  RecursiveCharacterTextSplitter \n",
    "from langchain.vectorstores import FAISS \n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50f9ab6c-d311-476f-8250-b0cb63c50f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from website\n",
    "url = \"https://utsavdesai26.medium.com/linear-regression-made-simple-a-step-by-step-tutorial-fb8e737ea2d9\"\n",
    "loader = WebBaseLoader(url)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14b02ad5-6567-4be9-a9b2-b78ca7bd6cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spplit data into chunks\n",
    "text_splitter  = RecursiveCharacterTextSplitter(chunk_size=  1000 , chunk_overlap=100)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa0200a2-7555-4238-abc5-703a660da7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings() \n",
    "vectorstore = FAISS.from_documents(texts , embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9907628-1b30-4ce1-9aca-1f868cb3dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4eed6f2-e112-47f9-83aa-84efa2a32390",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"What are the types of relationships between independent variables ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7c69fe1-b821-49cc-b96d-0e31a2c80166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b224cbcb-409d-4173-93be-55411dab146c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='may need to transform data to make the relationship linear (e.g. log transform for an exponential relationship).Little or No Multicollinearity between features: Multicollinearity exists when the independent variables are found to be moderately or highly correlated. In a model with correlated variables, it becomes a tough task to figure out the true relationship of predictors with the target variable. In other words, it becomes difficult to find out which variable is actually contributing to predict the response variable.Little or No Autocorrelation in residuals: The presence of correlation in error terms drastically reduces the model’s accuracy. This usually occurs in time series models where the next instant is dependent on the previous instant. If the error terms are correlated, the estimated standard errors tend to underestimate the true standard error.No Heteroscedasticity: The presence of non-constant variance in the error terms results in heteroscedasticity. Generally,', metadata={'source': 'https://utsavdesai26.medium.com/linear-regression-made-simple-a-step-by-step-tutorial-fb8e737ea2d9', 'title': 'Linear Regression Made Simple: A Step-by-Step Tutorial | by Utsav Desai | Medium', 'description': 'Linear Regression is a supervised learning algorithm in machine learning, which is widely used for solving regression problems. Regression is a type of machine learning problem where the goal is to…', 'language': 'en'}),\n",
       " Document(page_content='we are trying to predict), x is the independent variable (the predictor or feature), b0 is the intercept term (the value of y when x is zero), and b1 is the slope coefficient (the change in y for a unit change in x).The goal of Linear Regression is to find the best values for b0 and b1 such that the line best fits the data points, minimizing the errors or the difference between the predicted values and the actual values.Types of Linear Regression?There are two main types of Linear Regression models: Simple Linear Regression and Multiple Linear Regression.Simple Linear Regression: In simple linear regression, there is only one independent variable (also known as the predictor or feature) and one dependent variable (also known as the response variable). The goal of simple linear regression is to find the best-fitting line to describe the relationship between the independent and dependent variable. The equation for a simple linear regression model can be written as:Y = b0 + b1 * XHere, Y', metadata={'source': 'https://utsavdesai26.medium.com/linear-regression-made-simple-a-step-by-step-tutorial-fb8e737ea2d9', 'title': 'Linear Regression Made Simple: A Step-by-Step Tutorial | by Utsav Desai | Medium', 'description': 'Linear Regression is a supervised learning algorithm in machine learning, which is widely used for solving regression problems. Regression is a type of machine learning problem where the goal is to…', 'language': 'en'}),\n",
       " Document(page_content='between the predicted values and the actual values. Linear regression is widely used in many real-world applications, such as finance, marketing, and healthcare, for predicting outcomes such as stock prices, customer behavior, and patient outcomes.Linear Regression LineIn machine learning, a regression line can show two types of relationships between the input variables (also known as predictors or features) and the output variable (also known as the response variable) in a linear regression model.Positive Relationship: A positive relationship exists between the input variables and the output variable when the slope of the regression line is positive. In other words, as the values of the input variables increase, the value of the output variable also increases. This can be seen as an upward slope on a scatter plot of the data.Negative Relationship: A negative relationship exists between the input variables and the output variable when the slope of the regression line is negative. In', metadata={'source': 'https://utsavdesai26.medium.com/linear-regression-made-simple-a-step-by-step-tutorial-fb8e737ea2d9', 'title': 'Linear Regression Made Simple: A Step-by-Step Tutorial | by Utsav Desai | Medium', 'description': 'Linear Regression is a supervised learning algorithm in machine learning, which is widely used for solving regression problems. Regression is a type of machine learning problem where the goal is to…', 'language': 'en'}),\n",
       " Document(page_content='The equation for a simple linear regression model can be written as:Y = b0 + b1 * XHere, Y is the dependent variable, X is the independent variable, b0 is the intercept term, and b1 is the slope coefficient.Multiple Linear Regression: In multiple linear regression, there are multiple independent variables and one dependent variable. The goal of multiple linear regression is to find the best-fitting line to describe the relationship between the independent variables and the dependent variable. The equation for a multiple linear regression model can be written as:Y = b0 + b1 * X1 + b2 * X2 + … + bn * XnHere, Y is the dependent variable, X1, X2, …, Xn are the independent variables, b0 is the intercept term, and b1, b2, …, bn are the slope coefficients.In both types of linear regression, the goal is to find the best values for the intercept and slope coefficients that minimize the difference between the predicted values and the actual values. Linear regression is widely used in many', metadata={'source': 'https://utsavdesai26.medium.com/linear-regression-made-simple-a-step-by-step-tutorial-fb8e737ea2d9', 'title': 'Linear Regression Made Simple: A Step-by-Step Tutorial | by Utsav Desai | Medium', 'description': 'Linear Regression is a supervised learning algorithm in machine learning, which is widely used for solving regression problems. Regression is a type of machine learning problem where the goal is to…', 'language': 'en'})]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95370c2f-75e2-495c-87d0-bd584371cf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import  HypotheticalDocumentEmbedder\n",
    "llm = ChatOpenAI()\n",
    "hyde = HypotheticalDocumentEmbedder.from_llm(llm=llm ,base_embeddings=embeddings , prompt_key='web_search' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5533f4e1-c4b6-4f38-9f7b-b17d75a2a7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyde_db = FAISS.from_documents(texts , hyde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9dd740dd-fbdc-44bb-9e4b-545257bcb39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='between the predicted values and the actual values. Linear regression is widely used in many real-world applications, such as finance, marketing, and healthcare, for predicting outcomes such as stock prices, customer behavior, and patient outcomes.Linear Regression LineIn machine learning, a regression line can show two types of relationships between the input variables (also known as predictors or features) and the output variable (also known as the response variable) in a linear regression model.Positive Relationship: A positive relationship exists between the input variables and the output variable when the slope of the regression line is positive. In other words, as the values of the input variables increase, the value of the output variable also increases. This can be seen as an upward slope on a scatter plot of the data.Negative Relationship: A negative relationship exists between the input variables and the output variable when the slope of the regression line is negative. In', metadata={'source': 'https://utsavdesai26.medium.com/linear-regression-made-simple-a-step-by-step-tutorial-fb8e737ea2d9', 'title': 'Linear Regression Made Simple: A Step-by-Step Tutorial | by Utsav Desai | Medium', 'description': 'Linear Regression is a supervised learning algorithm in machine learning, which is widely used for solving regression problems. Regression is a type of machine learning problem where the goal is to…', 'language': 'en'}),\n",
       " Document(page_content='may need to transform data to make the relationship linear (e.g. log transform for an exponential relationship).Little or No Multicollinearity between features: Multicollinearity exists when the independent variables are found to be moderately or highly correlated. In a model with correlated variables, it becomes a tough task to figure out the true relationship of predictors with the target variable. In other words, it becomes difficult to find out which variable is actually contributing to predict the response variable.Little or No Autocorrelation in residuals: The presence of correlation in error terms drastically reduces the model’s accuracy. This usually occurs in time series models where the next instant is dependent on the previous instant. If the error terms are correlated, the estimated standard errors tend to underestimate the true standard error.No Heteroscedasticity: The presence of non-constant variance in the error terms results in heteroscedasticity. Generally,', metadata={'source': 'https://utsavdesai26.medium.com/linear-regression-made-simple-a-step-by-step-tutorial-fb8e737ea2d9', 'title': 'Linear Regression Made Simple: A Step-by-Step Tutorial | by Utsav Desai | Medium', 'description': 'Linear Regression is a supervised learning algorithm in machine learning, which is widely used for solving regression problems. Regression is a type of machine learning problem where the goal is to…', 'language': 'en'}),\n",
       " Document(page_content='we are trying to predict), x is the independent variable (the predictor or feature), b0 is the intercept term (the value of y when x is zero), and b1 is the slope coefficient (the change in y for a unit change in x).The goal of Linear Regression is to find the best values for b0 and b1 such that the line best fits the data points, minimizing the errors or the difference between the predicted values and the actual values.Types of Linear Regression?There are two main types of Linear Regression models: Simple Linear Regression and Multiple Linear Regression.Simple Linear Regression: In simple linear regression, there is only one independent variable (also known as the predictor or feature) and one dependent variable (also known as the response variable). The goal of simple linear regression is to find the best-fitting line to describe the relationship between the independent and dependent variable. The equation for a simple linear regression model can be written as:Y = b0 + b1 * XHere, Y', metadata={'source': 'https://utsavdesai26.medium.com/linear-regression-made-simple-a-step-by-step-tutorial-fb8e737ea2d9', 'title': 'Linear Regression Made Simple: A Step-by-Step Tutorial | by Utsav Desai | Medium', 'description': 'Linear Regression is a supervised learning algorithm in machine learning, which is widely used for solving regression problems. Regression is a type of machine learning problem where the goal is to…', 'language': 'en'}),\n",
       " Document(page_content='The equation for a simple linear regression model can be written as:Y = b0 + b1 * XHere, Y is the dependent variable, X is the independent variable, b0 is the intercept term, and b1 is the slope coefficient.Multiple Linear Regression: In multiple linear regression, there are multiple independent variables and one dependent variable. The goal of multiple linear regression is to find the best-fitting line to describe the relationship between the independent variables and the dependent variable. The equation for a multiple linear regression model can be written as:Y = b0 + b1 * X1 + b2 * X2 + … + bn * XnHere, Y is the dependent variable, X1, X2, …, Xn are the independent variables, b0 is the intercept term, and b1, b2, …, bn are the slope coefficients.In both types of linear regression, the goal is to find the best values for the intercept and slope coefficients that minimize the difference between the predicted values and the actual values. Linear regression is widely used in many', metadata={'source': 'https://utsavdesai26.medium.com/linear-regression-made-simple-a-step-by-step-tutorial-fb8e737ea2d9', 'title': 'Linear Regression Made Simple: A Step-by-Step Tutorial | by Utsav Desai | Medium', 'description': 'Linear Regression is a supervised learning algorithm in machine learning, which is widely used for solving regression problems. Regression is a type of machine learning problem where the goal is to…', 'language': 'en'})]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyde_retriever = hyde_db.as_retriever()\n",
    "hyde_retriever.invoke(\"What are the types of relationships between independent variables ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a20db59-95c3-46eb-b43a-12debd19c23b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
